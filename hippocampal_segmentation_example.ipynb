{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hippocampal Cell Segmentation with CellSeg3D\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Extract hippocampal ROIs using atlas registration (zarrnii)\n",
    "2. Run 3D cell segmentation using CellSeg3D models\n",
    "3. Perform instance segmentation to identify individual cells\n",
    "4. Extract quantitative statistics per region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "\n",
    "# zarrnii for ROI extraction\n",
    "from zarrnii import ZarrNii, ZarrNiiAtlas\n",
    "\n",
    "# CellSeg3D for segmentation\n",
    "from napari_cellseg3d.predict import inference_on_np3d\n",
    "from napari_cellseg3d.code_models.instance_segmentation import (\n",
    "    binary_watershed,\n",
    "    binary_connected,\n",
    "    voronoi_otsu,\n",
    "    volume_stats\n",
    ")\n",
    "from napari_cellseg3d.create_model import create_model\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ZARR_PATH = '/nfs/trident3/lightsheet/prado/mouse_app_lecanemab_ki3/bids/sub-AS134F3/micr/sub-AS134F3_sample-brain_acq-imaris4x_SPIM.ome.zarr'\n",
    "ATLAS_PATH = '/nfs/trident3/lightsheet/prado/mouse_app_lecanemab_ki3/derivatives/spimquant_aae813e/sub-AS134F3/micr/sub-AS134F3_sample-brain_acq-imaris4x_seg-all_from-ABAv3_level-5_desc-deform_dseg.nii.gz'\n",
    "ATLAS_TSV = '/nfs/trident3/lightsheet/prado/mouse_app_lecanemab_ki3/derivatives/spimquant_aae813e/tpl-ABAv3/seg-all_tpl-ABAv3_dseg.tsv'\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'device': 'cuda',  # Change to 'cpu' if no GPU available\n",
    "    'num_classes': 2,  # Background + cells\n",
    "    'model_weight_path': 'path/to/your/trained_model.pth',  # UPDATE THIS\n",
    "    'input_brightness_range': None,  # Auto-detect from data\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 1,\n",
    "}\n",
    "\n",
    "# Channels to process\n",
    "CHANNELS = ['Iba1', 'Abeta']\n",
    "\n",
    "# Brain regions to analyze\n",
    "REGIONS = {\n",
    "    'Left_Hippocampus': 'Left Hipp',\n",
    "    'Right_Hippocampus': 'Right Hipp',\n",
    "    'Left_CA1': 'Left.*Field CA1',\n",
    "    'Right_CA1': 'Right.*Field CA1',\n",
    "}\n",
    "\n",
    "# Processing parameters\n",
    "RESOLUTION_LEVEL = 0  # 0=full resolution, 2=intermediate (4x downsampled)\n",
    "ROI_SIZE = [64, 64, 64]  # Sliding window size for inference\n",
    "OUTPUT_DIR = Path('./segmentation_results')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Atlas and Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load atlas\n",
    "print(\"Loading atlas...\")\n",
    "atlas = ZarrNiiAtlas.from_files(ATLAS_PATH, ATLAS_TSV)\n",
    "print(f\"Atlas loaded: {len(atlas.labels_df)} regions\")\n",
    "\n",
    "# Display available regions\n",
    "atlas.labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract ROIs for Each Region and Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(zarr_path, channel, region_regex, atlas, level=0):\n",
    "    \"\"\"Extract ROI for a specific channel and brain region.\"\"\"\n",
    "    img = ZarrNii.from_ome_zarr(\n",
    "        zarr_path,\n",
    "        channel_labels=[channel],\n",
    "        level=level,\n",
    "        downsample_near_isotropic=False  # Keep original resolution for segmentation\n",
    "    )\n",
    "    \n",
    "    # Get bounding box from atlas\n",
    "    bbox = atlas.get_region_bounding_box(regex=region_regex)\n",
    "    \n",
    "    # Crop to region\n",
    "    roi = img.crop_with_bounding_box(*bbox, ras_coords=True)\n",
    "    \n",
    "    # Convert to numpy (remove channel dimension)\n",
    "    roi_data = np.array(roi.data[0])  # Shape: (Z, Y, X)\n",
    "    \n",
    "    print(f\"  Extracted {channel} - {region_regex}: shape={roi_data.shape}, \"\n",
    "          f\"dtype={roi_data.dtype}, range=[{roi_data.min()}, {roi_data.max()}]\")\n",
    "    \n",
    "    return roi_data, roi\n",
    "\n",
    "# Extract all ROIs\n",
    "rois = {}\n",
    "for region_name, region_regex in REGIONS.items():\n",
    "    print(f\"\\nProcessing region: {region_name}\")\n",
    "    rois[region_name] = {}\n",
    "    \n",
    "    for channel in CHANNELS:\n",
    "        try:\n",
    "            roi_data, roi_obj = extract_roi(\n",
    "                ZARR_PATH, channel, region_regex, atlas, level=RESOLUTION_LEVEL\n",
    "            )\n",
    "            rois[region_name][channel] = {\n",
    "                'data': roi_data,\n",
    "                'roi_obj': roi_obj\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR extracting {channel}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize ROIs (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mip(data, title=\"\"):\n",
    "    \"\"\"Plot maximum intensity projections along each axis.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(data.max(axis=0), cmap='gray')\n",
    "    axes[0].set_title(f\"{title} - Z projection\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(data.max(axis=1), cmap='gray')\n",
    "    axes[1].set_title(f\"{title} - Y projection\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(data.max(axis=2), cmap='gray')\n",
    "    axes[2].set_title(f\"{title} - X projection\")\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first region\n",
    "first_region = list(REGIONS.keys())[0]\n",
    "for channel in CHANNELS:\n",
    "    if channel in rois[first_region]:\n",
    "        plot_mip(rois[first_region][channel]['data'], f\"{first_region} - {channel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Cell Segmentation\n",
    "\n",
    "This performs:\n",
    "1. **Semantic segmentation**: Probability maps from CellSeg3D model\n",
    "2. **Instance segmentation**: Separate individual cells using watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_cells(roi_data, config, roi_size=[64, 64, 64], method='watershed'):\n",
    "    \"\"\"\n",
    "    Run full segmentation pipeline on a 3D ROI.\n",
    "    \n",
    "    Args:\n",
    "        roi_data: 3D numpy array (Z, Y, X)\n",
    "        config: Model configuration dict\n",
    "        roi_size: Sliding window size for inference\n",
    "        method: 'watershed', 'connected', or 'voronoi'\n",
    "    \n",
    "    Returns:\n",
    "        instance_labels: 3D array with unique label for each cell\n",
    "        prob_map: Foreground probability map\n",
    "    \"\"\"\n",
    "    print(\"  Running semantic segmentation (CellSeg3D)...\")\n",
    "    \n",
    "    # Semantic segmentation (probability maps)\n",
    "    prob_maps = inference_on_np3d(config, roi_data, roi_size)\n",
    "    \n",
    "    # Extract foreground probability (class 1)\n",
    "    foreground_prob = prob_maps[0, 1].cpu().numpy()\n",
    "    \n",
    "    print(f\"  Probability map range: [{foreground_prob.min():.3f}, {foreground_prob.max():.3f}]\")\n",
    "    \n",
    "    # Instance segmentation\n",
    "    print(f\"  Running instance segmentation ({method})...\")\n",
    "    \n",
    "    if method == 'watershed':\n",
    "        instance_labels = binary_watershed(\n",
    "            foreground_prob,\n",
    "            thres_objects=0.3,      # Foreground threshold\n",
    "            thres_seeding=0.9,      # Seed threshold\n",
    "            thres_small=30,         # Remove objects < 30 voxels\n",
    "            rem_seed_thres=3        # Remove seeds < 3 voxels\n",
    "        )\n",
    "    elif method == 'connected':\n",
    "        instance_labels = binary_connected(\n",
    "            foreground_prob,\n",
    "            thres=0.8,\n",
    "            thres_small=30\n",
    "        )\n",
    "    elif method == 'voronoi':\n",
    "        instance_labels = voronoi_otsu(\n",
    "            foreground_prob,\n",
    "            spot_sigma=2.0,\n",
    "            outline_sigma=2.0,\n",
    "            remove_small_size=30\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    n_cells = len(np.unique(instance_labels)) - 1  # Exclude background\n",
    "    print(f\"  Detected {n_cells} cells\")\n",
    "    \n",
    "    return instance_labels, foreground_prob\n",
    "\n",
    "# Run segmentation on all ROIs\n",
    "segmentation_results = {}\n",
    "\n",
    "for region_name in tqdm(REGIONS.keys(), desc=\"Regions\"):\n",
    "    print(f\"\\nSegmenting {region_name}...\")\n",
    "    segmentation_results[region_name] = {}\n",
    "    \n",
    "    for channel in CHANNELS:\n",
    "        if channel not in rois[region_name]:\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Channel: {channel}\")\n",
    "        roi_data = rois[region_name][channel]['data']\n",
    "        \n",
    "        try:\n",
    "            instance_labels, prob_map = segment_cells(\n",
    "                roi_data, \n",
    "                MODEL_CONFIG, \n",
    "                roi_size=ROI_SIZE,\n",
    "                method='watershed'\n",
    "            )\n",
    "            \n",
    "            segmentation_results[region_name][channel] = {\n",
    "                'instance_labels': instance_labels,\n",
    "                'prob_map': prob_map\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR during segmentation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Quantitative Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect statistics for all regions\n",
    "all_stats = []\n",
    "\n",
    "for region_name in REGIONS.keys():\n",
    "    for channel in CHANNELS:\n",
    "        if channel not in segmentation_results[region_name]:\n",
    "            continue\n",
    "            \n",
    "        instance_labels = segmentation_results[region_name][channel]['instance_labels']\n",
    "        \n",
    "        print(f\"\\n{region_name} - {channel}:\")\n",
    "        stats = volume_stats(instance_labels)\n",
    "        \n",
    "        if stats is not None:\n",
    "            print(f\"  Total cells: {stats.number_objects}\")\n",
    "            print(f\"  Mean volume: {np.mean(stats.volume):.2f} voxels\")\n",
    "            print(f\"  Std volume: {np.std(stats.volume):.2f} voxels\")\n",
    "            print(f\"  Filling ratio: {stats.filling_ratio[0]:.4f}\")\n",
    "            \n",
    "            # Create per-cell dataframe\n",
    "            df = pd.DataFrame({\n",
    "                'region': region_name,\n",
    "                'channel': channel,\n",
    "                'cell_id': range(len(stats.volume)),\n",
    "                'volume': stats.volume,\n",
    "                'centroid_x': stats.centroid_x,\n",
    "                'centroid_y': stats.centroid_y,\n",
    "                'centroid_z': stats.centroid_z,\n",
    "                'sphericity': stats.sphericity_ax\n",
    "            })\n",
    "            all_stats.append(df)\n",
    "\n",
    "# Combine all statistics\n",
    "if len(all_stats) > 0:\n",
    "    stats_df = pd.concat(all_stats, ignore_index=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    stats_csv = OUTPUT_DIR / 'cell_statistics.csv'\n",
    "    stats_df.to_csv(stats_csv, index=False)\n",
    "    print(f\"\\nStatistics saved to: {stats_csv}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary by region and channel:\")\n",
    "    summary = stats_df.groupby(['region', 'channel']).agg({\n",
    "        'cell_id': 'count',\n",
    "        'volume': ['mean', 'std'],\n",
    "        'sphericity': 'mean'\n",
    "    })\n",
    "    summary.columns = ['cell_count', 'mean_volume', 'std_volume', 'mean_sphericity']\n",
    "    display(summary)\n",
    "else:\n",
    "    print(\"No statistics to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(raw, prob_map, instance_labels, title=\"\"):\n",
    "    \"\"\"Visualize segmentation results with MIP.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    \n",
    "    # Z projection\n",
    "    axes[0, 0].imshow(raw.max(0), cmap='gray')\n",
    "    axes[0, 0].set_title(f\"{title}\\nRaw (Z proj)\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(prob_map.max(0), cmap='hot', vmin=0, vmax=1)\n",
    "    axes[0, 1].set_title(\"Probability Map (Z proj)\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(instance_labels.max(0), cmap='nipy_spectral')\n",
    "    axes[0, 2].set_title(f\"Instance Labels (Z proj)\\n{len(np.unique(instance_labels))-1} cells\")\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Y projection\n",
    "    axes[1, 0].imshow(raw.max(1), cmap='gray')\n",
    "    axes[1, 0].set_title(\"Raw (Y proj)\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(prob_map.max(1), cmap='hot', vmin=0, vmax=1)\n",
    "    axes[1, 1].set_title(\"Probability Map (Y proj)\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    axes[1, 2].imshow(instance_labels.max(1), cmap='nipy_spectral')\n",
    "    axes[1, 2].set_title(\"Instance Labels (Y proj)\")\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    # X projection\n",
    "    axes[2, 0].imshow(raw.max(2), cmap='gray')\n",
    "    axes[2, 0].set_title(\"Raw (X proj)\")\n",
    "    axes[2, 0].axis('off')\n",
    "    \n",
    "    axes[2, 1].imshow(prob_map.max(2), cmap='hot', vmin=0, vmax=1)\n",
    "    axes[2, 1].set_title(\"Probability Map (X proj)\")\n",
    "    axes[2, 1].axis('off')\n",
    "    \n",
    "    axes[2, 2].imshow(instance_labels.max(2), cmap='nipy_spectral')\n",
    "    axes[2, 2].set_title(\"Instance Labels (X proj)\")\n",
    "    axes[2, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results for each region/channel\n",
    "for region_name in REGIONS.keys():\n",
    "    for channel in CHANNELS:\n",
    "        if channel not in segmentation_results[region_name]:\n",
    "            continue\n",
    "            \n",
    "        raw = rois[region_name][channel]['data']\n",
    "        prob_map = segmentation_results[region_name][channel]['prob_map']\n",
    "        instance_labels = segmentation_results[region_name][channel]['instance_labels']\n",
    "        \n",
    "        visualize_segmentation(raw, prob_map, instance_labels, f\"{region_name} - {channel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save instance labels as TIFF files\n",
    "for region_name in REGIONS.keys():\n",
    "    for channel in CHANNELS:\n",
    "        if channel not in segmentation_results[region_name]:\n",
    "            continue\n",
    "            \n",
    "        instance_labels = segmentation_results[region_name][channel]['instance_labels']\n",
    "        prob_map = segmentation_results[region_name][channel]['prob_map']\n",
    "        \n",
    "        # Save instance labels\n",
    "        labels_path = OUTPUT_DIR / f\"{region_name}_{channel}_instance_labels.tif\"\n",
    "        tifffile.imwrite(labels_path, instance_labels.astype(np.uint32))\n",
    "        print(f\"Saved: {labels_path}\")\n",
    "        \n",
    "        # Save probability map\n",
    "        prob_path = OUTPUT_DIR / f\"{region_name}_{channel}_probability_map.tif\"\n",
    "        tifffile.imwrite(prob_path, prob_map.astype(np.float32))\n",
    "        print(f\"Saved: {prob_path}\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Cell Density Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cell density (cells per mm^3)\n",
    "# You'll need to know the voxel size from your imaging parameters\n",
    "\n",
    "if len(all_stats) > 0:\n",
    "    # Example: adjust these based on your actual voxel size\n",
    "    VOXEL_SIZE_MM = (0.001625, 0.001625, 0.0022010)  # X, Y, Z in mm from zarrnii_example\n",
    "    voxel_volume_mm3 = np.prod(VOXEL_SIZE_MM)\n",
    "    \n",
    "    density_stats = []\n",
    "    \n",
    "    for region_name in REGIONS.keys():\n",
    "        for channel in CHANNELS:\n",
    "            if channel not in segmentation_results[region_name]:\n",
    "                continue\n",
    "                \n",
    "            instance_labels = segmentation_results[region_name][channel]['instance_labels']\n",
    "            \n",
    "            n_cells = len(np.unique(instance_labels)) - 1\n",
    "            volume_voxels = instance_labels.size\n",
    "            volume_mm3 = volume_voxels * voxel_volume_mm3\n",
    "            density = n_cells / volume_mm3\n",
    "            \n",
    "            density_stats.append({\n",
    "                'region': region_name,\n",
    "                'channel': channel,\n",
    "                'n_cells': n_cells,\n",
    "                'volume_mm3': volume_mm3,\n",
    "                'density_per_mm3': density\n",
    "            })\n",
    "    \n",
    "    density_df = pd.DataFrame(density_stats)\n",
    "    density_csv = OUTPUT_DIR / 'cell_density.csv'\n",
    "    density_df.to_csv(density_csv, index=False)\n",
    "    \n",
    "    print(\"\\nCell Density Summary:\")\n",
    "    display(density_df)\n",
    "    print(f\"\\nDensity statistics saved to: {density_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Model Training**: If you don't have a trained model, you'll need to:\n",
    "   - Create training data (manual annotations)\n",
    "   - Train a CellSeg3D model on your specific cell type\n",
    "   - See `train.py` and training notebook examples\n",
    "\n",
    "2. **Parameter Tuning**: Adjust instance segmentation thresholds based on your data:\n",
    "   - `thres_objects`: Lower to detect dimmer cells\n",
    "   - `thres_seeding`: Lower to split touching cells more aggressively\n",
    "   - `thres_small`: Adjust minimum cell size\n",
    "\n",
    "3. **Multi-Channel Analysis**: \n",
    "   - Co-localization analysis between Iba1+ cells and Abeta plaques\n",
    "   - Distance measurements\n",
    "   - Spatial statistics\n",
    "\n",
    "4. **Batch Processing**: Process multiple subjects in parallel\n",
    "\n",
    "5. **Quality Control**: Visually inspect results and adjust parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
